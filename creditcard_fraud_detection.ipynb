{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3f0da292-2c5e-40f5-972e-b420f787c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in d:\\anaconda\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\anaconda\\lib\\site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: colorlog in d:\\anaconda\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\anaconda\\lib\\site-packages (from optuna) (2.0.30)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in d:\\anaconda\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in d:\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4 in d:\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\anaconda\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install optuna\n",
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6ae1aa-26a5-41f3-bd38-6f385ce88c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ends\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 20:22:15,789] A new study created in memory with name: no-name-c19f8726-2c4b-422b-80b0-eab3c577de9f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03915e8fc4f4f87995fdfdccf5c4629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  3.3min remaining:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 20:27:03,938] Trial 0 finished with value: 0.9941209573888117 and parameters: {'n_estimators': 40, 'max_depth': 96}. Best is trial 0 with value: 0.9941209573888117.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   47.1s remaining:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 20:28:14,814] Trial 1 finished with value: 0.9563441956984331 and parameters: {'n_estimators': 17, 'max_depth': 7}. Best is trial 0 with value: 0.9941209573888117.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  2.2min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 20:31:31,680] Trial 2 finished with value: 0.9940664403918189 and parameters: {'n_estimators': 28, 'max_depth': 90}. Best is trial 0 with value: 0.9941209573888117.\n",
      "The best parameter combination is: {'n_estimators': 40, 'max_depth': 96}\n",
      " The best score is: [0.9941209573888117]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold,cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "#read creditcaed.csv file chunk by chunk since this data is pretty huge up to 280 thousands.\n",
    "def chunck_read_csv(file_path,chunk_size):\n",
    "    '''\n",
    "    read big data chunk by chunk.\n",
    "    read_columns:a list containing the column names in the file you want to read\n",
    "\n",
    "    '''\n",
    "    df=pd.read_csv(file_path,header=0,iterator=True)\n",
    "    chunks=[]\n",
    "    loop=True\n",
    "    while loop:\n",
    "        try:\n",
    "            chunk=df.get_chunk(chunk_size)\n",
    "            chunks.append(chunk)\n",
    "        except StopIteration:\n",
    "            loop=False\n",
    "            print('reading ends')\n",
    "        df2=pd.concat(chunks,ignore_index=True)\n",
    "    return df2 \n",
    "    \n",
    "df=chunck_read_csv(r'E:\\Python datasets\\creditcard.csv',10000)\n",
    "\n",
    "# Before analysis, preprocess the data.\n",
    "# First ,delete the column 'Time' since it is not useful.\n",
    "del df['Time']\n",
    "#Second ,check the existence of NA value.\n",
    "na_check=df.isnull()\n",
    "# Count the number of NA value in the whole dataframe\n",
    "na_check.apply(lambda x: (x == True).sum()).sum()\n",
    "# Since the above output 0, there is no NA value.\n",
    "# Also,since the column 'Amount' obviously greater than any other features,it is easier to be overvalued, \n",
    "# therefore it need to be rescaled.\n",
    "df['Amount']=pd.Series(StandardScaler().fit_transform(df['Amount'].values[:,np.newaxis]).ravel())\n",
    "\n",
    "# From the code below, the class label is extremely unbalanced, therefore, oversampling or udnersampling should be employed,\n",
    "# since undersampling decrease sample size too much, oversampoling is used.\n",
    "df['Class'].value_counts()\n",
    "# Use SMOTE to conduct oversampling\n",
    "smote=SMOTE(random_state=1412)\n",
    "x,y=smote.fit_resample(df.iloc[:,:-1],df.iloc[:,-1])\n",
    "df=pd.concat([x,y],axis=1)\n",
    "# After oversampling, check the class label, the numbers of each catagory is balanced.\n",
    "df['Class'].value_counts()\n",
    "\n",
    "# Since the data has about 30 features, to decrease calculation and avoid overfitting, dimensionality reduction should be employed\n",
    "pca=PCA(n_components=4,random_state=1412)\n",
    "x=pca.fit_transform(df.iloc[:,:-1])\n",
    "# Check the cumulative contribution rate with code below, it is approximately 89.68% thought to be high enough\n",
    "pca.explained_variance_ratio_.sum()\n",
    "# Generate dataframe after pca\n",
    "y=df['Class'].values\n",
    "data=np.concatenate((x,y[:,np.newaxis]),axis=1)\n",
    "\n",
    "# Since the sample size is huge, here I use randomforest\n",
    "# Define the objective function of Bayesian Optimization\n",
    "def optuna_obj(trial):\n",
    "# Set parameter range\n",
    "    n_estimators=trial.suggest_int('n_estimators',10,50)\n",
    "    max_depth=trial.suggest_int('max_depth',3,100)\n",
    "# Instancize classifier\n",
    "    clf=RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,random_state=1412)\n",
    "# Set reviewer\n",
    "    cv=KFold(n_splits=10,shuffle=True,random_state=1412)\n",
    "    val_accuracy=cross_validate(clf,x,y,scoring='accuracy',cv=cv,verbose=True,n_jobs=-1)\n",
    "    return np.mean(val_accuracy['test_score'])\n",
    "#Caculate best_patams and best_score\n",
    "def optuna_optimizer(n_trials):\n",
    "    study=optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=20,n_ei_candidates=30),direction='maximize')\n",
    "    study.optimize(optuna_obj,n_trials=n_trials,show_progress_bar=True)\n",
    "    return study.best_trial.params,study.best_trial.values\n",
    "# Since the dataset is pretty huge, even if the Bayesian Optimization still costs pretty much time,\n",
    "# therefore, for simplicity, 'n_trials' here is set to be 3.\n",
    "best_params,best_score=optuna_optimizer(3)\n",
    "print(f'The best parameter combination is: {best_params}\\n The best score is: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82597014-48d1-4331-9ea3-5289d2e59212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above result,We find the best combination of best parameter and its corresponding best score.\n",
    "# Then we just need to substitute the result into model and get a good classifier.\n",
    "final_clf=RandomForestClassifier(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth'],random_state=1412)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
